{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a101e22a",
   "metadata": {},
   "source": [
    " llm store knowloedg in para meters means moree parmeter so more knowledge \n",
    "\n",
    " incontext learling   learn from prompt exmaple and give more relavent asnwer \n",
    "\n",
    "  indexing is external knowlegdge base is creates in rag and derive context the aswer as the query is given \n",
    "\n",
    " indexing is making external knowledge base \n",
    "\n",
    " finding content is reteraval \n",
    "\n",
    " prpmt creation and reterived content is generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36573676",
   "metadata": {},
   "source": [
    "Document ingestion : from were we have our document first we take out in our working momory so we can perform work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67defa5",
   "metadata": {},
   "source": [
    "text chuncking : large doc is converted into small chunk and break the context length of the system \n",
    "\n",
    "text splitter recursive text splitter one of them \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b3ea8",
   "metadata": {},
   "source": [
    "Embedding : After chunking we converting the vectors into embedding \n",
    "\n",
    "and then we search the sementic search \n",
    "\n",
    "the sementic search is between embedded docs\n",
    "\n",
    "open ai embedding   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1584f0",
   "metadata": {},
   "source": [
    "each chunk we have one denve vector and now we store in vector database \n",
    "\n",
    ": store vector incuded with original chunck text  with meta data three things included\n",
    "\n",
    "fiass chroma \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad454750",
   "metadata": {},
   "source": [
    "now we use the external knowledge base to seach in it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7630b",
   "metadata": {},
   "source": [
    "then user ask the question \n",
    "\n",
    "and multiple query is output for query ,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c8e67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "reterivaer :\n",
    "gerate embeding of the query as same embed model \n",
    "\n",
    "then you seach the vector the really close tothe quey \n",
    "\n",
    "afer getting the multiple output \n",
    "we use re ranking algorith so get max logical output \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4809cb",
   "metadata": {},
   "source": [
    "Augementation is not only query we inject our context in the query and context compbine  and give it to the llm \n",
    "\n",
    "to generate the output of the asnwer "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

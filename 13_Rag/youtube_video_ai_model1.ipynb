{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c79bf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MUHAMMAD\\miniconda3\\envs\\DS-ML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transcript loaded for: Cyv-dgv80kE\n",
      "✅ Transcript loaded for: yF9kGESAi3M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi , TranscriptsDisabled\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=api_key)\n",
    "\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_ids = [\"Cyv-dgv80kE\", \"yF9kGESAi3M\"]\n",
    "all_transcripts = []\n",
    "\n",
    "for video_id in video_ids:\n",
    "    try:\n",
    "        transcript_chunks = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "        text = \" \".join(chunk[\"text\"] for chunk in transcript_chunks)\n",
    "        all_transcripts.append(text)\n",
    "        print(f\"✅ Transcript loaded for: {video_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to get transcript for {video_id}: {e}\")\n",
    "\n",
    "full_transcript = \"\\n\\n\".join(all_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4f0c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m )\n\u001b[1;32m----> 2\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_transcripts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mlen\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\Users\\MUHAMMAD\\miniconda3\\envs\\DS-ML\\lib\\site-packages\\langchain_text_splitters\\base.py:79\u001b[0m, in \u001b[0;36mTextSplitter.create_documents\u001b[1;34m(self, texts, metadatas)\u001b[0m\n\u001b[0;32m     77\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     78\u001b[0m previous_chunk_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     80\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(_metadatas[i])\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_start_index:\n",
      "File \u001b[1;32mc:\\Users\\MUHAMMAD\\miniconda3\\envs\\DS-ML\\lib\\site-packages\\langchain_text_splitters\\character.py:126\u001b[0m, in \u001b[0;36mRecursiveCharacterTextSplitter.split_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Split the input text into smaller chunks based on predefined separators.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m        List[str]: A list of text chunks obtained after splitting.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_separators\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MUHAMMAD\\miniconda3\\envs\\DS-ML\\lib\\site-packages\\langchain_text_splitters\\character.py:88\u001b[0m, in \u001b[0;36mRecursiveCharacterTextSplitter._split_text\u001b[1;34m(self, text, separators)\u001b[0m\n\u001b[0;32m     86\u001b[0m     separator \u001b[38;5;241m=\u001b[39m _s\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_separator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     89\u001b[0m     separator \u001b[38;5;241m=\u001b[39m _s\n\u001b[0;32m     90\u001b[0m     new_separators \u001b[38;5;241m=\u001b[39m separators[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\n",
      "File \u001b[1;32mc:\\Users\\MUHAMMAD\\miniconda3\\envs\\DS-ML\\lib\\re.py:201\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=100 )\n",
    "chunks = text_splitter.create_documents([all_transcripts])\n",
    "len(chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
